import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras import layers
import glob


# ============ í•„ìš”í•œ í•¨ìˆ˜/í´ë˜ìŠ¤ ì •ì˜ ============
# 1. L1DistanceLayer ì •ì˜
class L1DistanceLayer(tf.keras.layers.Layer):
    """L1 ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ëŠ” ì»¤ìŠ¤í…€ ë ˆì´ì–´"""

    def __init__(self, **kwargs):
        super(L1DistanceLayer, self).__init__(**kwargs)

    def call(self, inputs):
        """ë‘ ì…ë ¥ í…ì„œ ê°„ì˜ L1 ê±°ë¦¬ ê³„ì‚°"""
        return tf.abs(inputs[0] - inputs[1])

    def compute_output_shape(self, input_shape):
        """ì¶œë ¥ í˜•íƒœ ê³„ì‚°"""
        return input_shape[0]

    def get_config(self):
        """ë ˆì´ì–´ ì„¤ì • ë°˜í™˜"""
        config = super(L1DistanceLayer, self).get_config()
        return config


# 2. contrastive_loss í•¨ìˆ˜ ì •ì˜
def contrastive_loss(y_true, y_pred, margin=1.0):
    """
    ì‹œì•” ë„¤íŠ¸ì›Œí¬ë¥¼ ìœ„í•œ ëŒ€ì¡° ì†ì‹¤ í•¨ìˆ˜
    y_true: 1ì´ë©´ ê°™ì€ í´ë˜ìŠ¤, 0ì´ë©´ ë‹¤ë¥¸ í´ë˜ìŠ¤
    y_pred: ë‘ ì…ë ¥ ì‚¬ì´ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬
    margin: ë‹¤ë¥¸ í´ë˜ìŠ¤ ìƒ˜í”Œ ê°„ ìµœì†Œ ê±°ë¦¬
    """
    y_true = tf.cast(y_true, tf.float32)
    square_pred = tf.square(y_pred)
    margin_square = tf.square(tf.maximum(margin - y_pred, 0))
    return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)


# 3. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_image(image_path, target_height=64, target_width=512):
    """í•„ê¸°ì²´ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ (ê°€ë¡œë¡œ ê¸´ ì´ë¯¸ì§€ ì²˜ë¦¬)"""
    try:
        # ì´ë¯¸ì§€ ë¡œë“œ
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")

        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(img.shape) == 3 and img.shape[2] == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img

        # ì›ë³¸ ì´ë¯¸ì§€ ìœ ì§€ (ìˆ˜ë™ íŠ¹ì§• ì¶”ì¶œìš©)
        original_gray = gray.copy()

        # ì´ì§„í™”
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

        # ë…¸ì´ì¦ˆ ì œê±°
        kernel = np.ones((2, 2), np.uint8)
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)

        # ì¢…íš¡ë¹„ ìœ ì§€ë¥¼ ìœ„í•œ ì²˜ë¦¬
        h, w = binary.shape
        aspect = w / h

        # ì¢…íš¡ë¹„ì— ë”°ë¥¸ ë¦¬ì‚¬ì´ì§• ì¡°ì •
        if aspect >= target_width / target_height:
            # ë„ˆë¹„ê°€ ë” ê¸¸ë©´ ë„ˆë¹„ì— ë§ì¶”ê³  ë†’ì´ ì¡°ì •
            new_width = target_width
            new_height = int(target_width / aspect)
            # ë†’ì´ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ìµœì†Œ ë†’ì´ ë³´ì¥
            if new_height < target_height / 2:
                new_height = target_height // 2
        else:
            # ë†’ì´ê°€ ë” ê¸¸ë©´ ë†’ì´ì— ë§ì¶”ê³  ë„ˆë¹„ ì¡°ì •
            new_height = target_height
            new_width = int(target_height * aspect)
            # ë„ˆë¹„ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ìµœì†Œ ë„ˆë¹„ ë³´ì¥
            if new_width < target_width / 2:
                new_width = target_width // 2

        # ë¦¬ì‚¬ì´ì§•
        resized = cv2.resize(binary, (new_width, new_height))

        # ê³ ì • í¬ê¸° ìº”ë²„ìŠ¤ ìƒì„± (íŒ¨ë”© ì ìš©)
        canvas = np.zeros((target_height, target_width), dtype=np.uint8)

        # ì¤‘ì•™ ë°°ì¹˜
        y_offset = (target_height - new_height) // 2
        x_offset = (target_width - new_width) // 2

        # ì´ë¯¸ì§€ ë³µì‚¬
        canvas[y_offset:y_offset + new_height, x_offset:x_offset + new_width] = resized

        # ì •ê·œí™”
        normalized = canvas.astype(np.float32) / 255.0

        # ì°¨ì› í™•ì¥ (H, W) -> (H, W, 1) - ëª…ì‹œì ìœ¼ë¡œ í˜•íƒœ í™•ì¸
        if len(normalized.shape) == 2:  # 2D ì´ë¯¸ì§€ì¸ ê²½ìš°
            expanded = np.expand_dims(normalized, axis=-1)
        else:
            expanded = normalized

        # í˜•íƒœ í™•ì¸ ë° ê°•ì œ ë³€í™˜
        if expanded.shape != (target_height, target_width, 1):
            expanded = np.reshape(expanded, (target_height, target_width, 1))

        # ìˆ˜ë™ íŠ¹ì§• ì¶”ì¶œ
        handcrafted_features = extract_handcrafted_features(original_gray, binary)

        return expanded, handcrafted_features

    except Exception as e:
        print(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì˜¤ë¥˜ ({image_path}): {e}")
        return None, None


# 4. ìˆ˜ë™ íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜
def extract_handcrafted_features(gray_img, binary_img=None):
    """í•„ê¸°ì²´ ì´ë¯¸ì§€ì—ì„œ ìˆ˜ë™ íŠ¹ì§• ì¶”ì¶œ"""
    features = []
    HANDCRAFTED_FEATURES_DIM = 12  # ìˆ˜ë™ ì¶”ì¶œ íŠ¹ì§• ì°¨ì›

    # ì´ì§„í™” ì´ë¯¸ì§€ê°€ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš°
    if binary_img is None:
        _, binary_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # 1. í”½ì…€ ë°€ë„ (í•„ì•• ê´€ë ¨)
    pixel_density = np.sum(binary_img > 0) / binary_img.size
    features.append(pixel_density)

    # 2. ìœ¤ê³½ì„  ì¶”ì¶œ
    contours, _ = cv2.findContours(binary_img.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # 3. ê¸°ìš¸ê¸° ë¶„ì„
    angles = []
    for contour in contours:
        if len(contour) > 5:  # íƒ€ì› í”¼íŒ…ì— í•„ìš”í•œ ìµœì†Œ í¬ì¸íŠ¸
            try:
                ellipse = cv2.fitEllipse(contour)
                angle = ellipse[2]
                # ê°ë„ í‘œì¤€í™” (0-180)
                if angle > 90:
                    angle = angle - 180
                angles.append(angle)
            except:
                pass

    # í‰ê·  ê¸°ìš¸ê¸°
    if angles:
        mean_angle = np.mean(angles)
        std_angle = np.std(angles)
    else:
        mean_angle = 0
        std_angle = 0

    features.append(mean_angle / 90)  # ì •ê·œí™”
    features.append(std_angle / 45)  # ì •ê·œí™”

    # 4. í¬ê¸° ë° ë¹„ìœ¨ ë¶„ì„
    if contours:
        heights = []
        widths = []
        areas = []
        aspect_ratios = []

        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            area = cv2.contourArea(contour)
            if area > 20:  # ë…¸ì´ì¦ˆ í•„í„°ë§
                heights.append(h)
                widths.append(w)
                areas.append(area)
                aspect_ratios.append(w / h if h > 0 else 0)

        if heights and widths:
            mean_height = np.mean(heights)
            std_height = np.std(heights)
            mean_width = np.mean(widths)
            std_width = np.std(widths)
            mean_area = np.mean(areas)
            mean_aspect = np.mean(aspect_ratios)
            std_aspect = np.std(aspect_ratios)
        else:
            mean_height = 0
            std_height = 0
            mean_width = 0
            std_width = 0
            mean_area = 0
            mean_aspect = 0
            std_aspect = 0
    else:
        mean_height = 0
        std_height = 0
        mean_width = 0
        std_width = 0
        mean_area = 0
        mean_aspect = 0
        std_aspect = 0

    features.append(mean_height / 100)  # ì •ê·œí™”
    features.append(std_height / 50)  # ì •ê·œí™”
    features.append(mean_width / 100)  # ì •ê·œí™”
    features.append(std_width / 50)  # ì •ê·œí™”
    features.append(mean_area / 1000)  # ì •ê·œí™”
    features.append(mean_aspect)
    features.append(std_aspect)

    # íŠ¹ì§•ì„ ìµœëŒ€ HANDCRAFTED_FEATURES_DIM ì°¨ì›ìœ¼ë¡œ ì œí•œ
    features = features[:HANDCRAFTED_FEATURES_DIM]

    # ë¶€ì¡±í•œ ì°¨ì›ì€ 0ìœ¼ë¡œ ì±„ì›€
    if len(features) < HANDCRAFTED_FEATURES_DIM:
        features.extend([0] * (HANDCRAFTED_FEATURES_DIM - len(features)))

    return np.array(features, dtype=np.float32)


# ============ ë©”ì¸ ì½”ë“œ ============
def get_similarity(model_path, image1_path, image2_path):
    """
    ë‘ ì´ë¯¸ì§€ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ê³  ë³€ìˆ˜ì— ì €ì¥

    Args:
        model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        image1_path: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ê²½ë¡œ
        image2_path: ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ ê²½ë¡œ

    Returns:
        float: similarity ê°’ (0~1)
    """
    # ì»¤ìŠ¤í…€ ê°ì²´ ì •ì˜
    custom_objects = {
        'L1DistanceLayer': L1DistanceLayer,
        'contrastive_loss': contrastive_loss
    }

    # ëª¨ë¸ ë¡œë“œ
    print(f"ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
    model = load_model(model_path, custom_objects=custom_objects)
    print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    print(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘: {image1_path}")
    img1_result = preprocess_image(image1_path)
    if img1_result[0] is None:
        print(f"ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {image1_path}")
        return None

    print(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘: {image2_path}")
    img2_result = preprocess_image(image2_path)
    if img2_result[0] is None:
        print(f"ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {image2_path}")
        return None

    img1, hand1 = img1_result
    img2, hand2 = img2_result

    # ë°°ì¹˜ í˜•íƒœë¡œ ë³€í™˜
    print("ì˜ˆì¸¡ ì¤€ë¹„ ì¤‘...")
    img1_batch = np.expand_dims(img1, axis=0)
    hand1_batch = np.expand_dims(hand1, axis=0)
    img2_batch = np.expand_dims(img2, axis=0)
    hand2_batch = np.expand_dims(hand2, axis=0)

    # ğŸ”¥ similarity ê°’ ê³„ì‚°í•˜ê³  ë³€ìˆ˜ì— ì €ì¥
    print("ìœ ì‚¬ë„ ê³„ì‚° ì¤‘...")
    similarity = model.predict([img1_batch, hand1_batch, img2_batch, hand2_batch])[0][0]

    # similarity ê°’ ì¶œë ¥
    print("=" * 50)
    print(f"Similarity: {similarity}")
    print(f"Similarity: {similarity:.4f}")  # ì†Œìˆ˜ì  4ìë¦¬ê¹Œì§€
    print("=" * 50)

    return similarity


# ============ ìƒˆë¡œìš´ í•¨ìˆ˜: ì°¸ì¡° í´ë” ë³€ê²½ ============
def compare_with_custom_references(model_path, test_image_path, reference_folder):
    """
    í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì™€ ì°¸ì¡° í´ë” ë‚´ì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ë¹„êµ

    Args:
        model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        test_image_path: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ
        reference_folder: ì°¸ì¡° ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œ
    """
    # ì°¸ì¡° í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    image_extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.tiff']
    reference_files = []

    for ext in image_extensions:
        reference_files.extend(glob.glob(os.path.join(reference_folder, ext)))
        reference_files.extend(glob.glob(os.path.join(reference_folder, ext.upper())))

    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì¢…ë£Œ
    if not reference_files:
        print(f"ì°¸ì¡° í´ë”ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {reference_folder}")
        return

    # ê° ì°¸ì¡° ì´ë¯¸ì§€ì™€ ë¹„êµ
    results = []
    for ref_path in reference_files:
        # ìœ ì‚¬ë„ ê³„ì‚°
        similarity_score = get_similarity(model_path, ref_path, test_image_path)

        if similarity_score is not None:
            # ê²°ê³¼ ì €ì¥
            results.append({
                'reference_path': ref_path,
                'reference_name': os.path.basename(ref_path),
                'similarity': similarity_score
            })

            # ì €ì¥ëœ similarity ê°’ ì‚¬ìš©
            print(f"ì €ì¥ëœ similarity: {similarity_score}")
            print(f"ê°™ì€ ì €ìì¸ê°€? {'YES' if similarity_score >= 0.5 else 'NO'}")

            # similarity ê°’ìœ¼ë¡œ ë‹¤ë¥¸ ì‘ì—…ë“¤
            if similarity_score > 0.8:
                print("ë§¤ìš° ë†’ì€ ìœ ì‚¬ë„!")
            elif similarity_score > 0.6:
                print("ë†’ì€ ìœ ì‚¬ë„")
            elif similarity_score > 0.4:
                print("ì¤‘ê°„ ìœ ì‚¬ë„")
            else:
                print("ë‚®ì€ ìœ ì‚¬ë„")

            print("\n" + "-" * 50 + "\n")

    # ê²°ê³¼ ìš”ì•½
    if results:
        # ê°€ì¥ ìœ ì‚¬í•œ ì´ë¯¸ì§€ ì°¾ê¸°
        max_similarity = max(results, key=lambda x: x['similarity'])

        print("\n" + "=" * 50)
        print(f"ê°€ì¥ ìœ ì‚¬í•œ ì°¸ì¡° ì´ë¯¸ì§€: {max_similarity['reference_name']}")
        print(f"ìœ ì‚¬ë„: {max_similarity['similarity']}")
        print("=" * 50)

    return results


# ê°„ë‹¨í•œ ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ëª¨ë¸ê³¼ ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •
    model_path = "handwriting_hybrid_model_1.keras"  # ëª¨ë¸ ê²½ë¡œ ìˆ˜ì •í•˜ì„¸ìš”

    # ğŸ‘‰ ì°¸ì¡° í´ë” ë³€ê²½ - ì´ ë¶€ë¶„ë§Œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤!
    reference_folder = "/Users/chanyoungko/Desktop/HandWriting/custom_references"  # ì°¸ì¡° í´ë” ê²½ë¡œ
    test_image_path = "/reference_samples/img.png"  # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    print("\n" + "=" * 50)
    print("í•„ê¸°ì²´ ë¹„êµ ì‹œìŠ¤í…œ")
    print("=" * 50)
    import os
    import cv2
    import numpy as np
    import tensorflow as tf
    from tensorflow.keras.models import load_model
    from tensorflow.keras import layers


    # ============ ì»¤ìŠ¤í…€ ë ˆì´ì–´ ============
    class L1DistanceLayer(tf.keras.layers.Layer):
        def __init__(self, **kwargs):
            super(L1DistanceLayer, self).__init__(**kwargs)

        def call(self, inputs):
            return tf.abs(inputs[0] - inputs[1])

        def compute_output_shape(self, input_shape):
            return input_shape[0]

        def get_config(self):
            config = super(L1DistanceLayer, self).get_config()
            return config


    # ============ ì†ì‹¤ í•¨ìˆ˜ ============
    def contrastive_loss(y_true, y_pred, margin=1.0):
        y_true = tf.cast(y_true, tf.float32)
        square_pred = tf.square(y_pred)
        margin_square = tf.square(tf.maximum(margin - y_pred, 0))
        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)


    # ============ ìˆ˜ë™ íŠ¹ì§• ì¶”ì¶œ ============
    def extract_handcrafted_features(gray_img, binary_img=None):
        features = []
        HANDCRAFTED_FEATURES_DIM = 12

        if binary_img is None:
            _, binary_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

        pixel_density = np.sum(binary_img > 0) / binary_img.size
        features.append(pixel_density)

        contours, _ = cv2.findContours(binary_img.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        angles = []
        for contour in contours:
            if len(contour) > 5:
                try:
                    ellipse = cv2.fitEllipse(contour)
                    angle = ellipse[2]
                    if angle > 90:
                        angle -= 180
                    angles.append(angle)
                except:
                    pass

        mean_angle = np.mean(angles) if angles else 0
        std_angle = np.std(angles) if angles else 0
        features.append(mean_angle / 90)
        features.append(std_angle / 45)

        heights, widths, areas, aspect_ratios = [], [], [], []
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            area = cv2.contourArea(contour)
            if area > 20:
                heights.append(h)
                widths.append(w)
                areas.append(area)
                aspect_ratios.append(w / h if h > 0 else 0)

        if heights and widths:
            features.extend([
                np.mean(heights) / 100,
                np.std(heights) / 50,
                np.mean(widths) / 100,
                np.std(widths) / 50,
                np.mean(areas) / 1000,
                np.mean(aspect_ratios),
                np.std(aspect_ratios)
            ])
        else:
            features.extend([0] * 7)

        features = features[:HANDCRAFTED_FEATURES_DIM]
        features.extend([0] * (HANDCRAFTED_FEATURES_DIM - len(features)))

        return np.array(features, dtype=np.float32)


    # ============ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ============
    def preprocess_image(image_path, target_height=64, target_width=512):
        try:
            img = cv2.imread(image_path)
            if img is None:
                raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")

            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
            original_gray = gray.copy()

            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, np.ones((2, 2), np.uint8))

            h, w = binary.shape
            aspect = w / h
            if aspect >= target_width / target_height:
                new_width = target_width
                new_height = max(int(target_width / aspect), target_height // 2)
            else:
                new_height = target_height
                new_width = max(int(target_height * aspect), target_width // 2)

            resized = cv2.resize(binary, (new_width, new_height))
            canvas = np.zeros((target_height, target_width), dtype=np.uint8)
            y_offset = (target_height - new_height) // 2
            x_offset = (target_width - new_width) // 2
            canvas[y_offset:y_offset + new_height, x_offset:x_offset + new_width] = resized

            normalized = canvas.astype(np.float32) / 255.0
            expanded = np.expand_dims(normalized, axis=-1)
            if expanded.shape != (target_height, target_width, 1):
                expanded = np.reshape(expanded, (target_height, target_width, 1))

            handcrafted_features = extract_handcrafted_features(original_gray, binary)
            return expanded, handcrafted_features

        except Exception as e:
            print(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì˜¤ë¥˜ ({image_path}): {e}")
            return None, None


    # ============ ìœ ì‚¬ë„ ê³„ì‚° ============
    def get_similarity(model, image1_path, image2_path):
        img1_result = preprocess_image(image1_path)
        img2_result = preprocess_image(image2_path)

        if img1_result[0] is None or img2_result[0] is None:
            return None

        img1, hand1 = img1_result
        img2, hand2 = img2_result

        img1_batch = np.expand_dims(img1, axis=0)
        hand1_batch = np.expand_dims(hand1, axis=0)
        img2_batch = np.expand_dims(img2, axis=0)
        hand2_batch = np.expand_dims(hand2, axis=0)

        similarity = model.predict([img1_batch, hand1_batch, img2_batch, hand2_batch])[0][0]

        print("=" * 50)
        print(f"[ë¹„êµ] {os.path.basename(image1_path)} vs {os.path.basename(image2_path)}")
        print(f"Similarity: {similarity:.4f}")
        print("=" * 50)
        return similarity


    def create_result(results):
        if not results:
            print("âŒ ë¹„êµí•  ê²°ê³¼ ì—†ìŒ")
            exit(1)

        best_result = results[0]

        #return AnalyzeResponse(best_result['avg_similarity'], best_result['avg_pressure'], best_result['avg_slant'], "")

    # ============ ë©”ì¸ ì‹¤í–‰ ============
    if __name__ == "__main__":
        model_path = "handwriting_hybrid_model_1.keras"
        reference_folder = "/Users/chanyoungko/Desktop/HandWriting/reference_samples"
        test_image_path = "/Users/chanyoungko/Desktop/HandWriting/test_samples/img.png"

        custom_objects = {
            'L1DistanceLayer': L1DistanceLayer,
            'contrastive_loss': contrastive_loss
        }

        print(f"ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
        model = load_model(model_path, custom_objects=custom_objects)
        print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        similarity_scores = []

        for filename in os.listdir(reference_folder):
            ref_path = os.path.join(reference_folder, filename)
            if os.path.isfile(ref_path) and filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                score = get_similarity(model, ref_path, test_image_path)
                if score is not None:
                    similarity_scores.append(score)

        if similarity_scores:
            avg_score = np.mean(similarity_scores)
            print("\n" + "#" * 50)
            print(f"ğŸ” ì „ì²´ í‰ê·  ìœ ì‚¬ë„: {avg_score:.4f}")
            print(f"âœ”ï¸ ë¹„êµí•œ ì´ë¯¸ì§€ ìˆ˜: {len(similarity_scores)}")
            print("#" * 50)
        else:
            print("âŒ ìœ ì‚¬ë„ ê³„ì‚°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        if similarity_scores:
            avg_score = np.mean(similarity_scores)
            print("\n" + "#" * 50)
            print(f"ğŸ” ì „ì²´ í‰ê·  ìœ ì‚¬ë„: {avg_score:.4f}")
            print(f"âœ”ï¸ ë¹„êµí•œ ì´ë¯¸ì§€ ìˆ˜: {len(similarity_scores)}")

            # Threshold ë¹„êµ
            threshold = 0.5
            print("#" * 50)
            if avg_score >= threshold:
                print(f"âœ… íŒë³„ ê²°ê³¼: ê°™ì€ ì‚¬ëŒì…ë‹ˆë‹¤ (ìœ ì‚¬ë„ â‰¥ {threshold})")
            else:
                print(f"âŒ íŒë³„ ê²°ê³¼: ë‹¤ë¥¸ ì‚¬ëŒì…ë‹ˆë‹¤ (ìœ ì‚¬ë„ < {threshold})")
            print("#" * 50)
        else:
            print("âŒ ìœ ì‚¬ë„ ê³„ì‚°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")




    # ë˜ëŠ” ê°œë³„ ì´ë¯¸ì§€ ë¹„êµë¥¼ ì›í•˜ëŠ” ê²½ìš° (ì›ë˜ ì½”ë“œ)
    # image1_path = "/path/to/reference_image.png"
    # similarity_score = get_similarity(model_path, image1_path, test_image_path)
    #
    # if similarity_score is not None:
    #     # ì €ì¥ëœ similarity ê°’ ì‚¬ìš©
    #     print(f"ì €ì¥ëœ similarity: {similarity_score}")
    #     print(f"ê°™ì€ ì €ìì¸ê°€? {'YES' if similarity_score >= 0.5 else 'NO'}")
    #
    #     # similarity ê°’ìœ¼ë¡œ ë‹¤ë¥¸ ì‘ì—…ë“¤
    #     if similarity_score > 0.8:
    #         print("ë§¤ìš° ë†’ì€ ìœ ì‚¬ë„!")
    #     elif similarity_score > 0.6:
    #         print("ë†’ì€ ìœ ì‚¬ë„")
    #     elif similarity_score > 0.4:
    #         print("ì¤‘ê°„ ìœ ì‚¬ë„")
    #     else:
    #         print("ë‚®ì€ ìœ ì‚¬ë„")